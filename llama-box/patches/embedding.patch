diff --git a/include/llama.h b/include/llama.h
index f23355a6..96e16d89 100644
--- a/include/llama.h
+++ b/include/llama.h
@@ -1178,6 +1178,8 @@ extern "C" {
 
     LLAMA_API void llama_dump_timing_info_yaml(FILE * stream, const struct llama_context * ctx);
 
+    LLAMA_API bool llama_supports_embedding_only (const struct llama_context * ctx);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/src/llama.cpp b/src/llama.cpp
index a207451f..f635b15a 100644
--- a/src/llama.cpp
+++ b/src/llama.cpp
@@ -19158,3 +19158,7 @@ void llama_log_callback_default(ggml_log_level level, const char * text, void *
     fputs(text, stderr);
     fflush(stderr);
 }
+
+bool llama_supports_embedding_only(const struct llama_context * ctx) {
+    return !ctx->cparams.causal_attn;
+}
