diff --git a/src/llama.cpp b/src/llama.cpp
index 2274296b..6da453c3 100644
--- a/src/llama.cpp
+++ b/src/llama.cpp
@@ -8319,7 +8319,7 @@ static bool llm_load_tensors(
 
     // print memory requirements
     for (ggml_backend_buffer_t buf : model.bufs) {
-        LLAMA_LOG_INFO("%s: %10s buffer size = %8.2f MiB\n", __func__, ggml_backend_buffer_name(buf), ggml_backend_buffer_get_size(buf) / 1024.0 / 1024.0);
+      LLAMA_LOG_INFO("%s: %10s buffer size = %8.2f MiB, buffer layer count = %d\n", __func__, ggml_backend_buffer_name(buf), ggml_backend_buffer_get_size(buf) / 1024.0 / 1024.0, buft_layer_count[ggml_backend_buffer_get_type(buf)]);
     }
 
     // populate tensors_by_name
